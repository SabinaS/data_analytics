{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the entire file into a python array\n",
    "with open('yelp_train_academic_dataset_business.json', 'rb') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "# each element of 'data' is an individual JSON object.\n",
    "# i want to convert it into an *array* of JSON objects\n",
    "# which, in and of itself, is one large JSON object\n",
    "# basically... add square brackets to the beginning\n",
    "# and end, and have all the individual business JSON objects\n",
    "# separated by a comma\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_flat = []\n",
    "for i in range(0,len(data_df)):\n",
    "    df_flat.append(flatten(data_df['attributes'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'By Appointment Only': True},\n",
       " {u'Accepts Credit Cards': True,\n",
       "  u'Alcohol': u'none',\n",
       "  u'Ambience_casual': False,\n",
       "  u'Ambience_classy': False,\n",
       "  u'Ambience_divey': False,\n",
       "  u'Ambience_hipster': False,\n",
       "  u'Ambience_intimate': False,\n",
       "  u'Ambience_romantic': False,\n",
       "  u'Ambience_touristy': False,\n",
       "  u'Ambience_trendy': False,\n",
       "  u'Ambience_upscale': False,\n",
       "  u'Attire': u'casual',\n",
       "  u'Caters': False,\n",
       "  u'Delivery': False,\n",
       "  u'Good For Groups': True,\n",
       "  u'Good For_breakfast': False,\n",
       "  u'Good For_brunch': False,\n",
       "  u'Good For_dessert': False,\n",
       "  u'Good For_dinner': False,\n",
       "  u'Good For_latenight': False,\n",
       "  u'Good For_lunch': True,\n",
       "  u'Good for Kids': True,\n",
       "  u'Has TV': True,\n",
       "  u'Noise Level': u'average',\n",
       "  u'Outdoor Seating': False,\n",
       "  u'Parking_garage': False,\n",
       "  u'Parking_lot': True,\n",
       "  u'Parking_street': False,\n",
       "  u'Parking_valet': False,\n",
       "  u'Parking_validated': False,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': True,\n",
       "  u'Takes Reservations': False,\n",
       "  u'Waiter Service': True},\n",
       " {u'Accepts Credit Cards': True,\n",
       "  u'Ambience_casual': True,\n",
       "  u'Ambience_classy': False,\n",
       "  u'Ambience_divey': False,\n",
       "  u'Ambience_hipster': False,\n",
       "  u'Ambience_intimate': False,\n",
       "  u'Ambience_romantic': False,\n",
       "  u'Ambience_touristy': False,\n",
       "  u'Ambience_trendy': False,\n",
       "  u'Ambience_upscale': False,\n",
       "  u'Attire': u'casual',\n",
       "  u'Caters': False,\n",
       "  u'Delivery': False,\n",
       "  u'Good For Groups': True,\n",
       "  u'Good For_breakfast': False,\n",
       "  u'Good For_brunch': True,\n",
       "  u'Good For_dessert': False,\n",
       "  u'Good For_dinner': False,\n",
       "  u'Good For_latenight': False,\n",
       "  u'Good For_lunch': False,\n",
       "  u'Good for Kids': True,\n",
       "  u'Has TV': True,\n",
       "  u'Noise Level': u'quiet',\n",
       "  u'Outdoor Seating': False,\n",
       "  u'Parking_garage': False,\n",
       "  u'Parking_lot': True,\n",
       "  u'Parking_street': False,\n",
       "  u'Parking_valet': False,\n",
       "  u'Parking_validated': False,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': True,\n",
       "  u'Takes Reservations': False,\n",
       "  u'Waiter Service': True},\n",
       " {u'Accepts Credit Cards': True,\n",
       "  u'Attire': u'casual',\n",
       "  u'Delivery': False,\n",
       "  u'Good For Groups': True,\n",
       "  u'Parking_garage': False,\n",
       "  u'Parking_lot': True,\n",
       "  u'Parking_street': False,\n",
       "  u'Parking_valet': False,\n",
       "  u'Parking_validated': False,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': True,\n",
       "  u'Takes Reservations': False,\n",
       "  u'Wheelchair Accessible': True,\n",
       "  u'Wi-Fi': u'free'},\n",
       " {u'Attire': u'casual',\n",
       "  u'Has TV': False,\n",
       "  u'Outdoor Seating': False,\n",
       "  u'Take-out': True}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'By Appointment Only': 1},\n",
       " {u'Accepts Credit Cards': 1,\n",
       "  'Alcohol_none': 1,\n",
       "  u'Ambience_casual': 0,\n",
       "  u'Ambience_classy': 0,\n",
       "  u'Ambience_divey': 0,\n",
       "  u'Ambience_hipster': 0,\n",
       "  u'Ambience_intimate': 0,\n",
       "  u'Ambience_romantic': 0,\n",
       "  u'Ambience_touristy': 0,\n",
       "  u'Ambience_trendy': 0,\n",
       "  u'Ambience_upscale': 0,\n",
       "  'Attire_casual': 1,\n",
       "  u'Caters': 0,\n",
       "  u'Delivery': 0,\n",
       "  u'Good For Groups': 1,\n",
       "  u'Good For_breakfast': 0,\n",
       "  u'Good For_brunch': 0,\n",
       "  u'Good For_dessert': 0,\n",
       "  u'Good For_dinner': 0,\n",
       "  u'Good For_latenight': 0,\n",
       "  u'Good For_lunch': 1,\n",
       "  u'Good for Kids': 1,\n",
       "  u'Has TV': 1,\n",
       "  'Noise Level_average': 1,\n",
       "  u'Outdoor Seating': 0,\n",
       "  u'Parking_garage': 0,\n",
       "  u'Parking_lot': 1,\n",
       "  u'Parking_street': 0,\n",
       "  u'Parking_valet': 0,\n",
       "  u'Parking_validated': 0,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': 1,\n",
       "  u'Takes Reservations': 0,\n",
       "  u'Waiter Service': 1},\n",
       " {u'Accepts Credit Cards': 1,\n",
       "  u'Ambience_casual': 1,\n",
       "  u'Ambience_classy': 0,\n",
       "  u'Ambience_divey': 0,\n",
       "  u'Ambience_hipster': 0,\n",
       "  u'Ambience_intimate': 0,\n",
       "  u'Ambience_romantic': 0,\n",
       "  u'Ambience_touristy': 0,\n",
       "  u'Ambience_trendy': 0,\n",
       "  u'Ambience_upscale': 0,\n",
       "  'Attire_casual': 1,\n",
       "  u'Caters': 0,\n",
       "  u'Delivery': 0,\n",
       "  u'Good For Groups': 1,\n",
       "  u'Good For_breakfast': 0,\n",
       "  u'Good For_brunch': 1,\n",
       "  u'Good For_dessert': 0,\n",
       "  u'Good For_dinner': 0,\n",
       "  u'Good For_latenight': 0,\n",
       "  u'Good For_lunch': 0,\n",
       "  u'Good for Kids': 1,\n",
       "  u'Has TV': 1,\n",
       "  'Noise Level_quiet': 1,\n",
       "  u'Outdoor Seating': 0,\n",
       "  u'Parking_garage': 0,\n",
       "  u'Parking_lot': 1,\n",
       "  u'Parking_street': 0,\n",
       "  u'Parking_valet': 0,\n",
       "  u'Parking_validated': 0,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': 1,\n",
       "  u'Takes Reservations': 0,\n",
       "  u'Waiter Service': 1},\n",
       " {u'Accepts Credit Cards': 1,\n",
       "  'Attire_casual': 1,\n",
       "  u'Delivery': 0,\n",
       "  u'Good For Groups': 1,\n",
       "  u'Parking_garage': 0,\n",
       "  u'Parking_lot': 1,\n",
       "  u'Parking_street': 0,\n",
       "  u'Parking_valet': 0,\n",
       "  u'Parking_validated': 0,\n",
       "  u'Price Range': 1,\n",
       "  u'Take-out': 1,\n",
       "  u'Takes Reservations': 0,\n",
       "  u'Wheelchair Accessible': 1,\n",
       "  'Wi-Fi_free': 1},\n",
       " {'Attire_casual': 1, u'Has TV': 0, u'Outdoor Seating': 0, u'Take-out': 1}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in df_flat:\n",
    "    counter = counter +1\n",
    "#    assert counter <500\n",
    "    for key,value in i.iteritems():\n",
    "        change_list=[]\n",
    "        if value == True:\n",
    "            i[key] = 1\n",
    "        elif value == False:\n",
    "            i[key] = 0\n",
    "        else:\n",
    "            change_list.append([key,value])\n",
    "        for j in change_list:\n",
    "          #  print j\n",
    "            i[str(j[0]+'_'+str(j[1]))] = 1\n",
    "            del i[j[0]]\n",
    "       \n",
    "  #  print i\n",
    "df_flat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37938"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37938"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dictV', DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('linreg', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vec.fit_transform(df_flat)\n",
    "linreg = LinearRegression(fit_intercept=True) \n",
    "att_pipe = pipeline.Pipeline([\n",
    "  ('dictV', vec),\n",
    "  ('linreg', linreg)\n",
    "  ])\n",
    "att_pipe.fit(df_flat,data_df['stars'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump(att_pipe, open(\"attr_model.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "class flat_Transformer(sk.base.BaseEstimator, sk.base.TransformerMixin):        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_df):\n",
    "        import collections\n",
    "        def flatten(d, parent_key='', sep='_'):\n",
    "            items = []\n",
    "            for k, v in d.items():\n",
    "                new_key = parent_key + sep + k if parent_key else k\n",
    "                if isinstance(v, collections.MutableMapping):\n",
    "                    items.extend(flatten(v, new_key, sep=sep).items())\n",
    "                else:\n",
    "                    items.append((new_key, v))\n",
    "            return dict(items)\n",
    "        df_flat = []\n",
    "        for i in range(0,len(data_df)):\n",
    "            df_flat.append(flatten(data_df['attributes'][i]))\n",
    "    #    assert len(df_flat) == 37938\n",
    "        for i in df_flat:\n",
    "            for key,value in i.iteritems():\n",
    "                change_list=[]\n",
    "                if value == True:\n",
    "                    i[key] = 1\n",
    "                elif value == False:\n",
    "                    i[key] = 0\n",
    "                else:\n",
    "                    change_list.append([key,value])\n",
    "                for j in change_list:\n",
    "                    i[str(j[0]+'_'+str(j[1]))] = 1\n",
    "                    del i[j[0]]  \n",
    "        return df_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_trans = flat_Transformer()\n",
    "vec = DictVectorizer()\n",
    "att_X = pipeline.Pipeline([\n",
    "        ('flat',flat_trans),\n",
    "        ('dictV',vec)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_flat_2=flat_trans.transform(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('att_X_', Pipeline(steps=[('flat', flat_Transformer()), ('dictV', DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True))])), ('linreg', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_pipe = pipeline.Pipeline([\n",
    "  ('att_X_',att_X),\n",
    "  ('linreg', linreg)\n",
    "  ])\n",
    "att_pipe.fit(data_df,data_df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37938"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "dill.dump(att_pipe, open(\"attr_model.pkl\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.037490120007126"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record =     {\"business_id\": \"vcNAWiLM4dR7D2nwwJ7nCA\", \n",
    "              \"full_address\": \"4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ 85018\", \n",
    "              \"hours\": {\"Tuesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Friday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Monday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Wednesday\": {\"close\": \"17:00\", \"open\": \"08:00\"}, \"Thursday\": {\"close\": \"17:00\", \"open\": \"08:00\"}}, \n",
    "              \"open\": True, \n",
    "              \"categories\": [\"Doctors\", \"Health & Medical\"], \n",
    "              \"city\": \"Phoenix\", \"review_count\": 7, \n",
    "              \"name\": \"Eric Goldberg, MD\", \n",
    "              \"neighborhoods\": [], \n",
    "              \"longitude\": -111.98375799999999, \n",
    "              \"state\": \"AZ\", \"stars\": 3.5, \n",
    "              \"latitude\": 33.499313000000001, \n",
    "              \"attributes\": {\"By Appointment Only\": True}, \"type\": \"business\"}\n",
    "att_pipe.predict(pd.DataFrame([record]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################categories transformer#################################\n",
    "class CategoryTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_df):\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        str1=[]\n",
    "        for i in data_df['categories']:\n",
    "            str1.append( str(' '.join(i)))\n",
    "        tf = TfidfVectorizer(analyzer='word', stop_words = 'english')        \n",
    "        return tf.fit_transform(str1).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################lat long tranformer##############################\n",
    "class ColumnSelectTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.k = 0\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array(X.loc[:,['latitude','longitude']]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37938, 832)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = CategoryTransformer()\n",
    "cat.transform(data_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################city tranformer##############################\n",
    "class CityTransformer(sk.base.BaseEstimator, sk.base.TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_df):       \n",
    "        return np.array(data_df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word', stop_words = 'english')  \n",
    "tf.fit_transform(data_df.loc[:,['city']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Phoenix', u'De Forest', u'De Forest', ..., u'Phoenix', u'Phoenix',\n",
       "       u'Edinburgh'], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(data_df['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ct = CityTransformer()\n",
    "ll = ColumnSelectTransformer()\n",
    "cat = CategoryTransformer()\n",
    "att_X = att_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes exactly 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-7c8f6c96ef57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[1;34m'att_X'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0matt_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   ])\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m k_union = pipeline.Pipeline([\n\u001b[0;32m      9\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    473\u001b[0m         transformers = Parallel(n_jobs=self.n_jobs)(\n\u001b[0;32m    474\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_one_transformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             for name, trans in self.transformer_list)\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit_one_transformer\u001b[1;34m(transformer, X, y)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_fit_one_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() takes exactly 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "all_features = pipeline.FeatureUnion([\n",
    "  ('ct', ct),\n",
    "  ('ll', ll),\n",
    "  ('cat',cat),\n",
    "  ('att_X',att_X)\n",
    "  ])\n",
    "all_features.fit(data_df)\n",
    "k_union = pipeline.Pipeline([\n",
    "  (\"features\", all_features),\n",
    "  (\"linreg\", LinearRegression(fit_intercept=True))\n",
    "  ])\n",
    "k_union.fit(data_df, data_df['stars'])\n",
    "K_union.predict(pd.DataFrame([record]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
